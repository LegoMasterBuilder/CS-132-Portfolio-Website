<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>PH Twitter Fake News Analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<style>
			pre code {
				background-color: #eee;
				border: 1px solid #000;
				display: block;
				padding: 1px;
				text-align: left;
			}
		</style>
	</head>
	<body class="is-preload">
		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="index.html">Home</a></li>
					<li><a href="about.html">About</a></li>
					<li><a href="datapreprocess.html">Data Preprocessing</a></li>
					<li><a href="visualization.html">Visualization</a></li>
					<li><a href="#results">Results</a></li>
				</ul>
			</nav>

		<!-- Home -->

		<!-- Results -->
		<article id="results" class="wrapper style3">
			<div class="container">
				<header>
					<h2>Data Visualization</h2>
					<p>Witness how the processed data is visually presented.</p>
				</header>

				<!-- <p>In order to transform our unstructured text data into a form fit for data analysis, there are several steps of preprocessing that need to be done. We begin with importing the data.</p> -->
				
				<h3>Visualization</h3>
				<p>
					These visualizations serve to aid the researchers in data processing and data analysis, as well as in presenting the data in an easily digestible format. The plots will be created using the `plotly` module.</p>
				<pre>
					<code>
	import pandas as pd
	data = pd.read_csv('g23dataset.csv')
	data = data.iloc[:150]
	data.head()
					</code>
				</pre>

				<h3>Plotting Token Count per Tweet</h3>
				<p>
                This can be used to roughly estimate the time and space complexity of data processing and analysis methods. This will be especially relevant when processing the tokens into n-grams or using methods that suffer from the curse of dimensionality. As sen in the plot below, around half of the tweets have token counts greater than or equal to 20, which might significantly increase processing time of the afforementioned methods.
				<pre>
					<code>
# Get token counts of tweets
tweet_token_count = []

for i in range(len(tweets)):
    tok_list = tweets[0][i]
    tweet_token_count.append(len(tok_list))

tok_count = []
tok_count_freq = []

for n in set(tweet_token_count):
    tok_count.append(n)
    tok_count_freq.append(tweet_token_count.count(n))

# tok_count_df = pd.DataFrame.from_dict(tok_count_freq, orient='index')
# tok_count_df.rename(columns = {0:'Token Count Frequency'}, inplace = True)
tok_count_df = pd.DataFrame({'Token Count': tok_count, 'Frequency of Token Count': tok_count_freq})
# tok_count_df

# print(tok_count_freq)
    
# Plot token counts in Histogram

import plotly.express as px
fig = px.histogram(tok_count_df, x='Token Count', y='Frequency of Token Count', title='Frequency of Token Counts in Tweets')
fig.show()
fig.write_html("tokcountfreq.html")
                    </code>
                </pre>

			<h4>Histogram of token count</h4>
            <embed type="text/html" src="tokcountfreq.html" width="1000" height="800">
			<p>This histogram shows the relationship between the token counts of the different tokenized words from the data set and their sume of frequency of token counts.</p>
			
				<h3>Displaying the most common tokens</h3>
				<p>
                This will be used to get an initial glimpse of the most common keywords before the data analysis and clustering.
				<pre>
					<code>
					all_tokens = []

for i in range(len(tweets)):
    all_tokens.extend(tweets[0][i])
    
tok = []
tok_freq = []

for n in set(all_tokens):
    tok_count = all_tokens.count(n)
    if tok_count > 15:
        tok.append(n)
        tok_freq.append(all_tokens.count(n))

tok_freq_df = pd.DataFrame({'Token': tok, 'Frequency of Token': tok_freq})
    
# Plot token frequency in Histogram

import plotly.express as px
fig = px.histogram(tok_freq_df, x='Token', y='Frequency of Token', title='Frequency of Tokens')
fig.show()
fig.write_html("tokfreq.html")
                    </code>
				</pre>

			<h4>Histogram of token frequency</h4>
            <embed type="text/html" src="tokfreq.html" width="1000" height="800">
            <img src="Wordcloud.png">
			<p>This histogram shows the relationship between the token counts of the different tokenized words from the data set and their sume of frequency of token counts.</p>
			
			</div>
		</article>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
