{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad79e25",
   "metadata": {},
   "source": [
    "# Preprocessing for NLP\n",
    "\n",
    "In order to transform our unstructured text data into a form fit for data analysis, there are several steps of preprocessing that need to be done. We begin with importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff8c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet URL</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collector</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Account handle</th>\n",
       "      <th>Account name</th>\n",
       "      <th>...</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet Translated</th>\n",
       "      <th>Tweet Type</th>\n",
       "      <th>Date posted</th>\n",
       "      <th>Screenshot</th>\n",
       "      <th>Content type</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23-1</td>\n",
       "      <td>13/03/23 13:25:32</td>\n",
       "      <td>https://twitter.com/GirlFromIhawan/status/1534...</td>\n",
       "      <td>23</td>\n",
       "      <td>Lorico, Hans Daniel</td>\n",
       "      <td>MRCS</td>\n",
       "      <td>Misinformation on Food Situation during Ferdin...</td>\n",
       "      <td>Kadiwa, agricultural, Masagana 99</td>\n",
       "      <td>@GirlFromIhawan</td>\n",
       "      <td>üî•WILD TONIGHTüî•</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes mare, panahon ni marcos sr. Nagawa na nila...</td>\n",
       "      <td>Yes friend, during the time of Marcos Sr., the...</td>\n",
       "      <td>Text, Reply</td>\n",
       "      <td>08/06/2022 12:48</td>\n",
       "      <td>https://drive.google.com/file/d/1weUGYhQjHZ9jg...</td>\n",
       "      <td>Rational</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23-2</td>\n",
       "      <td>13/03/23 13:45:32</td>\n",
       "      <td>https://twitter.com/kotomba431C/status/1306285...</td>\n",
       "      <td>23</td>\n",
       "      <td>Lorico, Hans Daniel</td>\n",
       "      <td>MRCS</td>\n",
       "      <td>Misinformation on Food Situation during Ferdin...</td>\n",
       "      <td>Nutribun, Panahon ni Marcos, mag-aaral</td>\n",
       "      <td>@kotomba431C</td>\n",
       "      <td>Kotomba Powder</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ito Ang Nutribun at Gatas na ibinibigay sa Mga...</td>\n",
       "      <td>This is the Nutribun and milk that was provide...</td>\n",
       "      <td>Text, Image</td>\n",
       "      <td>17/09/20 1:35</td>\n",
       "      <td>https://drive.google.com/file/d/1-MhBL8k7V3TBi...</td>\n",
       "      <td>Emotional</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23-3</td>\n",
       "      <td>13/03/23 13:50:32</td>\n",
       "      <td>https://twitter.com/indaysara/status/159141949...</td>\n",
       "      <td>23</td>\n",
       "      <td>Lorico, Hans Daniel</td>\n",
       "      <td>MRCS</td>\n",
       "      <td>Misinformation on Food Situation during Ferdin...</td>\n",
       "      <td>Nutribun, Marcos, nutrition, gulay</td>\n",
       "      <td>@indaysara</td>\n",
       "      <td>Sara Duterte</td>\n",
       "      <td>...</td>\n",
       "      <td>Davao City</td>\n",
       "      <td>Bilang pa-birthday, handog ni Sen. Imee ang mg...</td>\n",
       "      <td>For her birthday, Sen. Imee offers these nutri...</td>\n",
       "      <td>Text, Image, Reply</td>\n",
       "      <td>12/11/22 21:15</td>\n",
       "      <td>https://drive.google.com/file/d/1cs3B8smx65wTe...</td>\n",
       "      <td>Rational</td>\n",
       "      <td>191</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-4</td>\n",
       "      <td>31/03/23 10:35:49</td>\n",
       "      <td>https://twitter.com/aa_alegades/status/1108343...</td>\n",
       "      <td>23</td>\n",
       "      <td>Rosales, Christian Jay</td>\n",
       "      <td>MRCS</td>\n",
       "      <td>Misinformation on Food Situation during Ferdin...</td>\n",
       "      <td>Walang nagugutom, Marcos</td>\n",
       "      <td>@aa_alegades</td>\n",
       "      <td>Alegades</td>\n",
       "      <td>...</td>\n",
       "      <td>Quezon City, National Capital</td>\n",
       "      <td>Kay Marcos, walang nagugutom na estudyante! Sa...</td>\n",
       "      <td>Because of Marcos, no student was hungry. Than...</td>\n",
       "      <td>Text</td>\n",
       "      <td>20/03/19 20:25</td>\n",
       "      <td>https://drive.google.com/file/d/1HaNIoJc7WmieU...</td>\n",
       "      <td>Emotional</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-5</td>\n",
       "      <td>31/03/23 14:41:53</td>\n",
       "      <td>https://twitter.com/Yelle007/status/1303897326...</td>\n",
       "      <td>23</td>\n",
       "      <td>Rosales, Christian Jay</td>\n",
       "      <td>MRCS</td>\n",
       "      <td>Misinformation on Food Situation during Ferdin...</td>\n",
       "      <td>Walang nagugutom, Marcos</td>\n",
       "      <td>@Yelle007</td>\n",
       "      <td>Burger Ranger üçî‚úåÔ∏èüòä</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eschuzme! @dawende, noong time ni Marcos walan...</td>\n",
       "      <td>eschuzme! @dawende, nobody went hungry during ...</td>\n",
       "      <td>Text, Reply (comment)</td>\n",
       "      <td>09/10/20 11:25</td>\n",
       "      <td>https://drive.google.com/file/d/1iEKP_N0N-6fzM...</td>\n",
       "      <td>Emotional</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID          Timestamp                                          Tweet URL   \n",
       "0  23-1  13/03/23 13:25:32  https://twitter.com/GirlFromIhawan/status/1534...  \\\n",
       "1  23-2  13/03/23 13:45:32  https://twitter.com/kotomba431C/status/1306285...   \n",
       "2  23-3  13/03/23 13:50:32  https://twitter.com/indaysara/status/159141949...   \n",
       "3  23-4  31/03/23 10:35:49  https://twitter.com/aa_alegades/status/1108343...   \n",
       "4  23-5  31/03/23 14:41:53  https://twitter.com/Yelle007/status/1303897326...   \n",
       "\n",
       "  Group               Collector Category   \n",
       "0    23     Lorico, Hans Daniel     MRCS  \\\n",
       "1    23     Lorico, Hans Daniel     MRCS   \n",
       "2    23     Lorico, Hans Daniel     MRCS   \n",
       "3    23  Rosales, Christian Jay     MRCS   \n",
       "4    23  Rosales, Christian Jay     MRCS   \n",
       "\n",
       "                                               Topic   \n",
       "0  Misinformation on Food Situation during Ferdin...  \\\n",
       "1  Misinformation on Food Situation during Ferdin...   \n",
       "2  Misinformation on Food Situation during Ferdin...   \n",
       "3  Misinformation on Food Situation during Ferdin...   \n",
       "4  Misinformation on Food Situation during Ferdin...   \n",
       "\n",
       "                                 Keywords   Account handle   \n",
       "0       Kadiwa, agricultural, Masagana 99  @GirlFromIhawan  \\\n",
       "1  Nutribun, Panahon ni Marcos, mag-aaral     @kotomba431C   \n",
       "2      Nutribun, Marcos, nutrition, gulay       @indaysara   \n",
       "3                Walang nagugutom, Marcos     @aa_alegades   \n",
       "4                Walang nagugutom, Marcos        @Yelle007   \n",
       "\n",
       "         Account name  ...                       Location   \n",
       "0      üî•WILD TONIGHTüî•  ...                            NaN  \\\n",
       "1      Kotomba Powder  ...                            NaN   \n",
       "2        Sara Duterte  ...                     Davao City   \n",
       "3            Alegades  ...  Quezon City, National Capital   \n",
       "4  Burger Ranger üçî‚úåÔ∏èüòä  ...                            NaN   \n",
       "\n",
       "                                               Tweet   \n",
       "0  Yes mare, panahon ni marcos sr. Nagawa na nila...  \\\n",
       "1  Ito Ang Nutribun at Gatas na ibinibigay sa Mga...   \n",
       "2  Bilang pa-birthday, handog ni Sen. Imee ang mg...   \n",
       "3  Kay Marcos, walang nagugutom na estudyante! Sa...   \n",
       "4  eschuzme! @dawende, noong time ni Marcos walan...   \n",
       "\n",
       "                                    Tweet Translated             Tweet Type   \n",
       "0  Yes friend, during the time of Marcos Sr., the...            Text, Reply  \\\n",
       "1  This is the Nutribun and milk that was provide...            Text, Image   \n",
       "2  For her birthday, Sen. Imee offers these nutri...     Text, Image, Reply   \n",
       "3  Because of Marcos, no student was hungry. Than...                   Text   \n",
       "4  eschuzme! @dawende, nobody went hungry during ...  Text, Reply (comment)   \n",
       "\n",
       "        Date posted                                         Screenshot   \n",
       "0  08/06/2022 12:48  https://drive.google.com/file/d/1weUGYhQjHZ9jg...  \\\n",
       "1     17/09/20 1:35  https://drive.google.com/file/d/1-MhBL8k7V3TBi...   \n",
       "2    12/11/22 21:15  https://drive.google.com/file/d/1cs3B8smx65wTe...   \n",
       "3    20/03/19 20:25  https://drive.google.com/file/d/1HaNIoJc7WmieU...   \n",
       "4    09/10/20 11:25  https://drive.google.com/file/d/1iEKP_N0N-6fzM...   \n",
       "\n",
       "  Content type Likes Replies Retweets  \n",
       "0     Rational     1       0        0  \n",
       "1    Emotional    16       1        3  \n",
       "2     Rational   191      12       29  \n",
       "3    Emotional     0       1        0  \n",
       "4    Emotional     3       0        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('g23dataset.csv')\n",
    "data = data.iloc[:150]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58787d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61014985",
   "metadata": {},
   "source": [
    "It is important to tokenize the text to make sure NLP libraries can process the raw text. The Natural Language Toolkit (NLTK) python module will be used to tokenize the text. The text is transformed to lowercase to make sure the same word will not be treated as separate tokens during parsing. Punctuation and emoji will also be removed since they are not relevant in determining the main keywords used in the tweets. The stopwords will be removed using NLTK as a basis before tokenizing the text. To make sure that words with similar meanings are not treated as distinct tokens, it is also important to lemmatize the tokens. Lemmatization simplifies the word to its base meaning, known as its lemma, in order to have better results in data analysis. This allows similar words such as \"better\" and \"good\" to be processed as similar tokens. All of these preprocessing methods will be applied to the tweets in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeda0683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hanslorico/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hanslorico/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hanslorico/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NLTK and make sure the relevant libraries are downloaded\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252f819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[yes, friend, time, marcos, sr, able, masagana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nutribun, milk, provided, student, time, ferd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[birthday, sen, imee, offer, nutribuns, child,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[marcos, student, hungry, thanks, nutribun, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[eschuzme, dawende, nobody, went, hungry, marc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [yes, friend, time, marcos, sr, able, masagana...\n",
       "1  [nutribun, milk, provided, student, time, ferd...\n",
       "2  [birthday, sen, imee, offer, nutribuns, child,...\n",
       "3  [marcos, student, hungry, thanks, nutribun, ma...\n",
       "4  [eschuzme, dawende, nobody, went, hungry, marc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the tweets\n",
    "tweets = data['Tweet Translated'].dropna()\n",
    "\n",
    "# Convert all tweets to lowercase\n",
    "tweets = tweets.str.lower()\n",
    "\n",
    "# Remove punctuation from tweets, remove stopwords then tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "processed_text = []\n",
    "\n",
    "for text in tweets:\n",
    "    # Punctuation Removal\n",
    "    tok = ''.join([c for c in text if c.isalnum() or c == ' '])\n",
    "    \n",
    "    # Tokenization\n",
    "    tok_list = nltk.word_tokenize(tok)\n",
    "    \n",
    "    # Stopword Removal\n",
    "    tok_list = [word for word in tok_list if word not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tok_list = [lemmatizer.lemmatize(word) for word in tok_list]\n",
    "    \n",
    "    processed_text.append(tok_list)\n",
    "    \n",
    "tweets = pd.DataFrame([processed_text])\n",
    "\n",
    "tweets = tweets.transpose()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ab8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
